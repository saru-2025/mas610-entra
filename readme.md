
# ğŸ’¼ MAS610-ENTRA: Azure Regulatory Data Platform

### ğŸ“˜ Overview
**MAS610-ENTRA** is an end-to-end regulatory data platform built on **Azure Data Lake Gen2**, **Databricks**, and **Terraform** to automate **Monetary Authority of Singapore (MAS)** reporting â€” specifically returns **MAS 610, MAS 309, MAS 652, MAS 640**, and **MAS 1003/1303**, aligned to **Basel III/IV** frameworks.

The solution integrates ingestion, transformation, data quality, reconciliation, and CI/CD automation to deliver MAS-compliant financial, risk, and compliance reporting with full lineage, auditability, and scalability.

---

## ğŸ§  Key Objectives
- Automate **Regulatory Reporting** for MAS 610 and related Basel III/IV returns.  
- Establish a **Medallion Architecture (Bronze / Silver / Gold)** on Azure Data Lake.  
- Implement **Data Quality (DQ) & Reconciliation** frameworks for accuracy and completeness.  
- Enable **Model Governance** for PD/LGD/EAD and liquidity models via Databricks MLflow.  
- Provide **Continuous Integration / Deployment (CI/CD)** and **Infrastructure-as-Code (IaC)** using Terraform and GitHub Actions.  

---

## âš™ï¸ Architecture Overview
```text
Source Systems â†’ ADF Ingestion (Bronze) â†’ Databricks Transformations (Silver) â†’  
Regulatory Modeling & Aggregation (Gold) â†’ Power BI / MAS Returns â†’ DCG Submission
````

**Core Azure Components:**

* **Azure Data Lake Gen2** â€“ centralized data storage
* **Azure Databricks** â€“ PySpark transformation and ML governance
* **Azure Data Factory (ADF)** â€“ orchestration and scheduling
* **Azure Synapse** â€“ analytical layer and SQL-based aggregation
* **Azure Purview** â€“ lineage and governance
* **Azure Key Vault** â€“ secrets management
* **Terraform** â€“ infrastructure automation
* **Power BI** â€“ DQ dashboards and MAS report visualizations

---

## ğŸ§© Repository Structure

```
mas610-entra/
â”‚
â”œâ”€â”€ databricks/
â”‚   â”œâ”€â”€ notebooks/
â”‚   â”‚   â”œâ”€â”€ MAS610_Bronze_Load.py
â”‚   â”‚   â”œâ”€â”€ MAS610_Silver_Transform.py
â”‚   â”‚   â”œâ”€â”€ MAS610_Gold_Model.py
â”‚   â”‚   â”œâ”€â”€ DQ_Validation.py
â”‚   â”‚   â””â”€â”€ Reconciliation_Checks.py
â”‚   â””â”€â”€ jobs/
â”‚       â”œâ”€â”€ eventhub_producer.py
â”‚       â”œâ”€â”€ consumer_streaming_riskfeed.py
â”‚       â””â”€â”€ pipeline_trigger_config.json
â”‚
â”œâ”€â”€ adf_pipelines/
â”‚   â”œâ”€â”€ pipeline_ingestion.json
â”‚   â”œâ”€â”€ pipeline_dq_validation.json
â”‚   â”œâ”€â”€ pipeline_reconciliation.json
â”‚   â””â”€â”€ trigger_on_new_trade_file.json
â”‚
â”œâ”€â”€ sql_warehouse/
â”‚   â”œâ”€â”€ mas610_gold_views.sql
â”‚   â”œâ”€â”€ mas652_large_exposure.sql
â”‚   â”œâ”€â”€ dq_results_validation.sql
â”‚   â””â”€â”€ reconciliation_metrics.sql
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

---

## ğŸš€ Quick Start

### 1. Clone the repository

```bash
git clone https://github.com/saru-2025/mas610-entra.git
cd mas610-entra
```

### 2. Configure Azure authentication

```bash
az login --tenant "<tenant-id>"
az account set --subscription "<subscription-id>"
```

### 3. Deploy infrastructure using Terraform

```bash
cd terraform
terraform init
terraform plan
terraform apply -auto-approve
```

### 4. Configure Databricks CLI (with AAD token)

```bash
az login
token_response=$(az account get-access-token --resource 2ff814a6-3304-4ab8-85cb-cd0e6f879c1d)
export DATABRICKS_AAD_TOKEN=$(jq .accessToken -r <<< "$token_response")

databricks configure --aad-token
```

### 5. Run notebooks for ingestion and transformation

```bash
databricks workspace import_dir ./databricks/notebooks /Workspace/Shared/MAS610
databricks jobs create --json-file ./databricks/jobs/pipeline_trigger_config.json
```

---

## ğŸ§® Exercises (from Hands-On Coding Assessment)

| Exercise                               | Description                                                                              | Skill Area           |
| -------------------------------------- | ---------------------------------------------------------------------------------------- | -------------------- |
| **1. Real-Time Risk Feed**             | Kafka/EventHub â†’ Databricks Structured Streaming (5-min aggregation, DLQ, DQ validation) | Streaming + ETL      |
| **2. Regulatory Data Model (MAS 610)** | Transform `accounts`, `loans`, `collateral` CSVs â†’ MAS 610 Balance Sheet                 | SQL/PySpark Modeling |
| **3. CI/CD & IaC**                     | Automate Databricks deployment + Terraform cluster provisioning                          | DevOps & Automation  |

---

## ğŸ§  Data Quality & Reconciliation

* **DQ Rule Categories:** Completeness, Accuracy, Consistency, Timeliness
* **Rule Repository:** `dq_rule_master` (Delta Table)
* **Execution Framework:** ADF + Databricks Notebooks
* **Monitoring:** Power BI dashboards showing DQ scores, failed rules, and reconciliation variance (<0.1%)

---

## ğŸ§° Governance & Security

| Layer           | Control                      | Azure Service              |
| --------------- | ---------------------------- | -------------------------- |
| Identity        | Role-based access (RBAC/MFA) | Azure AD                   |
| Data Encryption | AES-256 / TLS 1.2+           | ADLS Gen2 + Key Vault      |
| Audit & Lineage | End-to-end traceability      | Azure Purview              |
| CI/CD Security  | Secrets scanning & approvals | GitHub Actions + Key Vault |
| Compliance      | MAS TRM, PDPA, ISO 27001     | Azure Policy + Sentinel    |

---

## ğŸ“Š Reporting and Visualization

* Power BI dashboards: DQ Scores, MAS Returns, Reconciliation Variance
* SQL Warehouse queries for MAS 610, 309, 652, 640
* Data exported as CSV/XML templates for MAS Data Collection Gateway (DCG)

---

## ğŸ§± Future Roadmap

* âœ… Real-time MAS 309 liquidity monitoring via Event Grid
* ğŸ¤– AI-driven DQ anomaly detection using Databricks AutoML
* ğŸŒ Cross-regulatory schema harmonization (MAS, HKMA, BNM)
* ğŸ§¾ Explainable AI (XAI) for PD/LGD and liquidity models
* ğŸŒ± ESG data integration and sustainability metrics

---

## ğŸ§‘â€ğŸ’» Contributors

**Author:** Saritha Mantripragada
**Role:** Senior Data Engineer / Lead Data Architect
**Focus:** Azure + Databricks Regulatory Data Platforms for BFSI

---

## ğŸ“œ License

This repository is licensed under the **MIT License**. See [LICENSE](LICENSE) for details.

